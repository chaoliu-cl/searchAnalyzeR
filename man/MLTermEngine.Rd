% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/term_suggestion_engine.r
\name{MLTermEngine}
\alias{MLTermEngine}
\title{ML Term Suggestion Engine}
\description{
A machine learning-based system for suggesting synonymous search terms that may
improve search performance. Uses semantic embeddings, biomedical ontologies,
and performance-based learning to recommend better search strategies.
}
\details{
This module provides intelligent term suggestion capabilities using machine learning
techniques to identify synonymous search terms with better performance potential.
ML Term Suggestion Engine

The MLTermEngine employs multiple ML techniques:
\itemize{
\item \strong{Semantic Embeddings}: Uses pre-trained biomedical word embeddings
\item \strong{Performance Learning}: Learns from historical search performance data
\item \strong{Ontology Integration}: Leverages biomedical ontologies (MeSH, UMLS)
\item \strong{Context Analysis}: Analyzes term co-occurrence patterns
\item \strong{Adaptive Ranking}: Uses ML models to rank term suggestions by predicted performance
}
}
\section{Methods}{

\describe{
\item{\code{new()}}{Initialize the term suggestion engine}
\item{\code{suggest_terms(terms, context, performance_data)}}{Generate synonym suggestions}
\item{\code{eval_suggestions(original_terms, suggested_terms, validation_corpus)}}{Evaluate suggestion quality}
\item{\code{train_model(historical_data)}}{Train ML model on performance data}
}
}

\examples{
# Initialize the ML term engine
engine <- MLTermEngine$new()

# Basic term suggestion
original_terms <- c("diabetes", "treatment", "clinical trial")
suggestions <- engine$suggest_terms(
  terms = original_terms,
  max_suggestions = 5,
  min_similarity = 0.7
)
print(suggestions)

# Evaluate suggestions with validation corpus
corpus <- data.frame(
  id = paste0("art", 1:100),
  title = paste("Research on", sample(c("diabetes", "diabetic", "glycemic"), 100, replace = TRUE)),
  abstract = paste("Study about", sample(c("treatment", "therapy", "intervention"), 100, replace = TRUE)),
  stringsAsFactors = FALSE
)

evaluation <- engine$eval_suggestions(
  original_terms = original_terms,
  suggested_terms = suggestions$terms,
  validation_corpus = corpus
)
print(evaluation)

}
\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{embedding_model}}{Trained embedding model for semantic similarity}

\item{\code{performance_model}}{ML model for predicting term performance}

\item{\code{ontology_cache}}{Cached ontology terms for quick lookup}

\item{\code{training_history}}{Historical performance data for model training}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-MLTermEngine-new}{\code{MLTermEngine$new()}}
\item \href{#method-MLTermEngine-suggest_terms}{\code{MLTermEngine$suggest_terms()}}
\item \href{#method-MLTermEngine-eval_suggestions}{\code{MLTermEngine$eval_suggestions()}}
\item \href{#method-MLTermEngine-train_model}{\code{MLTermEngine$train_model()}}
\item \href{#method-MLTermEngine-rank_terms}{\code{MLTermEngine$rank_terms()}}
\item \href{#method-MLTermEngine-clone}{\code{MLTermEngine$clone()}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-MLTermEngine-new"></a>}}
\if{latex}{\out{\hypertarget{method-MLTermEngine-new}{}}}
\subsection{Method \code{new()}}{
Initialize the Term Suggestion Engine with ML models and ontology data.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{MLTermEngine$new(load_pretrained = TRUE, cache_ontologies = TRUE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{load_pretrained}}{Logical, whether to load pre-trained biomedical embeddings}

\item{\code{cache_ontologies}}{Logical, whether to cache biomedical ontology data}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
No return value, called for side effects
Suggest synonymous terms using ML techniques
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-MLTermEngine-suggest_terms"></a>}}
\if{latex}{\out{\hypertarget{method-MLTermEngine-suggest_terms}{}}}
\subsection{Method \code{suggest_terms()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{MLTermEngine$suggest_terms(
  terms,
  context = NULL,
  performance_data = NULL,
  max_suggestions = 5,
  min_similarity = 0.6,
  include_variants = TRUE
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{terms}}{Character vector of original search terms}

\item{\code{context}}{Optional context information (domain, corpus type)}

\item{\code{performance_data}}{Optional historical performance data for terms}

\item{\code{max_suggestions}}{Maximum number of suggestions per term}

\item{\code{min_similarity}}{Minimum semantic similarity threshold (0-1)}

\item{\code{include_variants}}{Logical, whether to include morphological variants}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
List with suggested terms and their predicted performance scores
Evaluate quality of term suggestions
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-MLTermEngine-eval_suggestions"></a>}}
\if{latex}{\out{\hypertarget{method-MLTermEngine-eval_suggestions}{}}}
\subsection{Method \code{eval_suggestions()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{MLTermEngine$eval_suggestions(
  original_terms,
  suggested_terms,
  validation_corpus = NULL,
  gold_standard = NULL
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{original_terms}}{Character vector of original terms}

\item{\code{suggested_terms}}{Character vector of suggested terms}

\item{\code{validation_corpus}}{Data frame with corpus for validation (optional - will auto-generate if NULL)}

\item{\code{gold_standard}}{Optional vector of known relevant article IDs}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
Evaluation results comparing original vs suggested terms
Train performance prediction model from historical data
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-MLTermEngine-train_model"></a>}}
\if{latex}{\out{\hypertarget{method-MLTermEngine-train_model}{}}}
\subsection{Method \code{train_model()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{MLTermEngine$train_model(
  historical_data,
  model_type = "random_forest",
  cross_validate = TRUE
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{historical_data}}{Data frame with term performance history}

\item{\code{model_type}}{Type of ML model ("random_forest", "svm", "neural_network")}

\item{\code{cross_validate}}{Logical, whether to perform cross-validation}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
Trained model performance metrics
Get model-based term rankings
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-MLTermEngine-rank_terms"></a>}}
\if{latex}{\out{\hypertarget{method-MLTermEngine-rank_terms}{}}}
\subsection{Method \code{rank_terms()}}{
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{MLTermEngine$rank_terms(terms, context = NULL)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{terms}}{Character vector of terms to rank}

\item{\code{context}}{Optional context for prediction}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
Data frame with terms and predicted performance scores
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-MLTermEngine-clone"></a>}}
\if{latex}{\out{\hypertarget{method-MLTermEngine-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{MLTermEngine$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
